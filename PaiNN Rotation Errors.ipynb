{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import MessagePassing, radius_graph\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "import ase\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Func\n",
    "from torch.nn import Embedding, Sequential, Linear, ModuleList, Module\n",
    "import numpy as np\n",
    "from torch import linalg as LA\n",
    "import math\n",
    "\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineCutoff(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, cutoff=5.0):\n",
    "        super(CosineCutoff, self).__init__()\n",
    "        #self.register_buffer(\"cutoff\", torch.FloatTensor([cutoff]))\n",
    "        self.cutoff = cutoff\n",
    "\n",
    "    def forward(self, distances):\n",
    "        \"\"\"Compute cutoff.\n",
    "\n",
    "        Args:\n",
    "            distances (torch.Tensor): values of interatomic distances.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: values of cutoff function.\n",
    "\n",
    "        \"\"\"\n",
    "        # Compute values of cutoff function\n",
    "        cutoffs = 0.5 * (torch.cos(distances * np.pi / self.cutoff) + 1.0)\n",
    "        # Remove contributions beyond the cutoff radius\n",
    "        cutoffs *= (distances < self.cutoff).float()\n",
    "        return cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BesselBasis(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Sine for radial basis expansion with coulomb decay. (0th order Bessel from DimeNet)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cutoff=5.0, n_rbf=20):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cutoff: radial cutoff\n",
    "            n_rbf: number of basis functions.\n",
    "        \"\"\"\n",
    "        super(BesselBasis, self).__init__()\n",
    "        # compute offset and width of Gaussian functions\n",
    "        freqs = torch.arange(1, n_rbf + 1) * math.pi / cutoff\n",
    "        self.register_buffer(\"freqs\", freqs)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = torch.norm(inputs, p=2, dim=1)\n",
    "        a = self.freqs\n",
    "        ax = torch.outer(inputs,a)\n",
    "        sinax = torch.sin(ax)\n",
    "\n",
    "        norm = torch.where(inputs == 0, torch.tensor(1.0, device=inputs.device), inputs)\n",
    "        y = sinax / norm[:,None]\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaiNN(torch.nn.Module):\n",
    "    def __init__(self, num_feat, out_channels, num_nodes, cut_off=5.0, n_rbf=20, num_interactions=3):\n",
    "        super(PaiNN, self).__init__() \n",
    "        '''PyG implementation of PaiNN network of SchÃ¼tt et. al. Supports two arrays  \n",
    "           stored at the nodes of shape (num_nodes,num_feat,1) and (num_nodes, num_feat,3). For this \n",
    "           representation to be compatible with PyG, the arrays are flattened and concatenated. \n",
    "           Important to note is that the out_channels must match number of features'''\n",
    "        \n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_interactions = num_interactions\n",
    "        self.cut_off = cut_off\n",
    "        self.n_rbf = n_rbf\n",
    "        self.linear = Linear(num_feat,num_feat)\n",
    "        self.silu = Func.silu\n",
    "        \n",
    "        self.list_message = nn.ModuleList(\n",
    "            [\n",
    "                MessagePassPaiNN(num_feat, out_channels, num_nodes, cut_off, n_rbf)\n",
    "                for _ in range(self.num_interactions)\n",
    "            ]\n",
    "        )\n",
    "        self.list_update = nn.ModuleList(\n",
    "            [\n",
    "                UpdatePaiNN(num_feat, out_channels, num_nodes)\n",
    "                for _ in range(self.num_interactions)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, s,v, edge_index, edge_attr):\n",
    "        \n",
    "        \n",
    "        for i in range(self.num_interactions):\n",
    "            \n",
    "            s_temp,v_temp = self.list_message[i](s,v, edge_index, edge_attr)\n",
    "            s, v = s_temp+s, v_temp+v\n",
    "            s_temp,v_temp = self.list_update[i](s,v) \n",
    "            s, v = s_temp+s, v_temp+v       \n",
    "        \n",
    "        s = self.linear(s)\n",
    "        s = self.silu(s)\n",
    "        s = self.linear(s)\n",
    "        \n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessagePassPaiNN(MessagePassing):\n",
    "    def __init__(self, num_feat, out_channels, num_nodes, cut_off=5.0, n_rbf=20):\n",
    "        super(MessagePassPaiNN, self).__init__(aggr='add') \n",
    "        \n",
    "        self.lin1 = Linear(num_feat, out_channels) \n",
    "        self.lin2 = Linear(out_channels, 3*out_channels) \n",
    "        self.lin_rbf = Linear(n_rbf, 3*out_channels) \n",
    "        self.silu = Func.silu\n",
    "        \n",
    "        #self.prepare = Prepare_Message_Vector(num_nodes)\n",
    "        self.RBF = BesselBasis(cut_off, n_rbf)\n",
    "        self.f_cut = CosineCutoff(cut_off)\n",
    "        self.num_nodes = num_nodes\n",
    "    \n",
    "    def forward(self, s,v, edge_index, edge_attr):\n",
    "        \n",
    "        s = s.flatten(-1)\n",
    "        v = v.flatten(-2)\n",
    "        \n",
    "        flat_shape_v = v.shape[-1]\n",
    "        flat_shape_s = s.shape[-1]\n",
    "    \n",
    "        x =torch.cat([s, v], dim = -1)\n",
    "        \n",
    "        \n",
    "        x = self.propagate(edge_index, x=x, edge_attr=edge_attr\n",
    "                            ,flat_shape_s=flat_shape_s, flat_shape_v=flat_shape_v)\n",
    "            \n",
    "        return x    \n",
    "    \n",
    "    def message(self, x_j, edge_attr, flat_shape_s, flat_shape_v):\n",
    "        \n",
    "        \n",
    "        # Split Input into s_j and v_j\n",
    "        s_j, v_j = torch.split(x_j, [flat_shape_s, flat_shape_v], dim=-1)\n",
    "        \n",
    "        # r_ij channel\n",
    "        rbf = self.RBF(edge_attr)\n",
    "        ch1 = self.lin_rbf(rbf)\n",
    "        cut = self.f_cut(edge_attr.norm(dim=-1))\n",
    "        W = torch.einsum('ij,i->ij',ch1, cut) # ch1 * f_cut\n",
    "        \n",
    "        # s_j channel\n",
    "        phi = self.lin1(s_j)\n",
    "        phi = self.silu(phi)\n",
    "        phi = self.lin2(phi)\n",
    "        \n",
    "        # Split \n",
    "        left, dsm, right = torch.tensor_split(phi*W,3,dim=-1)\n",
    "        \n",
    "        # v_j channel\n",
    "        normalized = Func.normalize(edge_attr, p=2, dim=1)\n",
    "        \n",
    "        v_j = v_j.reshape(-1, int(flat_shape_v/3), 3)\n",
    "        hadamard_right = torch.einsum('ij,ik->ijk',right, normalized)\n",
    "        hadamard_left = torch.einsum('ijk,ij->ijk',v_j,left)\n",
    "        dvm = hadamard_left + hadamard_right \n",
    "        \n",
    "        # Prepare vector for update\n",
    "        x_j = torch.cat((dsm,dvm.flatten(-2)), dim=-1)\n",
    "       \n",
    "        return x_j\n",
    "    \n",
    "    def update(self, out_aggr,flat_shape_s, flat_shape_v):\n",
    "        \n",
    "        s_j, v_j = torch.split(out_aggr, [flat_shape_s, flat_shape_v], dim=-1)\n",
    "        \n",
    "        return s_j, v_j.reshape(-1, int(flat_shape_v/3), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdatePaiNN(torch.nn.Module):\n",
    "    def __init__(self, num_feat, out_channels, num_nodes):\n",
    "        super(UpdatePaiNN, self).__init__() \n",
    "        \n",
    "        self.lin_up = Linear(2*num_feat, out_channels) \n",
    "        self.denseU = Linear(num_feat,out_channels, bias = False) \n",
    "        self.denseV = Linear(num_feat,out_channels, bias = False) \n",
    "        self.lin2 = Linear(out_channels, 3*out_channels) \n",
    "        self.silu = Func.silu\n",
    "        \n",
    "        \n",
    "    def forward(self, s,v):\n",
    "        \n",
    "        # split and take linear combinations\n",
    "        #s, v = torch.split(out_aggr, [flat_shape_s, flat_shape_v], dim=-1)\n",
    "        \n",
    "        s = s.flatten(-1)\n",
    "        v = v.flatten(-2)\n",
    "        \n",
    "        flat_shape_v = v.shape[-1]\n",
    "        flat_shape_s = s.shape[-1]\n",
    "        \n",
    "        v_u = v.reshape(-1, int(flat_shape_v/3), 3)\n",
    "        v_ut = torch.transpose(v_u,1,2)\n",
    "        U = torch.transpose(self.denseU(v_ut),1,2)\n",
    "        V = torch.transpose(self.denseV(v_ut),1,2)\n",
    "        \n",
    "        \n",
    "        # form the dot product\n",
    "        UV =  torch.einsum('ijk,ijk->ij',U,V) \n",
    "        \n",
    "        # s_j channel\n",
    "        nV = torch.norm(V, dim=-1)\n",
    "\n",
    "        s_u = torch.cat([s, nV], dim=-1)\n",
    "        s_u = self.lin_up(s_u) \n",
    "        s_u = Func.silu(s_u)\n",
    "        s_u = self.lin2(s_u)\n",
    "        #s_u = Func.silu(s_u)\n",
    "        \n",
    "        # final split\n",
    "        top, middle, bottom = torch.tensor_split(s_u,3,dim=-1)\n",
    "        \n",
    "        # outputs\n",
    "        dvu = torch.einsum('ijk,ij->ijk',v_u,top) \n",
    "        dsu = middle*UV + bottom \n",
    "        \n",
    "        #update = torch.cat((dsu,dvu.flatten(-2)), dim=-1)\n",
    "        \n",
    "        return dsu, dvu.reshape(-1, int(flat_shape_v/3), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethanol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = 128\n",
    "num_nodes = 9\n",
    "s0 = torch.rand(num_nodes,F, dtype=torch.float)\n",
    "PA = PaiNN(F, F, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unrotated and Untranslated Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = 128\n",
    "num_nodes = 9\n",
    "\n",
    "v0 = torch.zeros(num_nodes,F,3, dtype=torch.float)\n",
    "\n",
    "r_ij = torch.tensor([[ 0.0072, -0.5687,  0.0000],\n",
    "        [-1.2854,  0.2499,  0.0000],\n",
    "        [ 1.1304,  0.3147,  0.0000],\n",
    "        [ 0.0392, -1.1972,  0.8900],\n",
    "        [ 0.0392, -1.1972, -0.8900],\n",
    "        [-1.3175,  0.8784,  0.8900],\n",
    "        [-1.3175,  0.8784, -0.8900],\n",
    "        [-2.1422, -0.4239,  0.0000],\n",
    "        [ 1.9857, -0.1365,  0.0000]], dtype = torch.float)\n",
    "\n",
    "# edge_attr: inter_atomic distances\n",
    "edge_index = radius_graph(r_ij, r=1.70, batch=None, loop=False)\n",
    "row, col = edge_index\n",
    "edge_attr = (r_ij[row] - r_ij[col])\n",
    "#print(edge_index.dtype == torch.long)\n",
    "\n",
    "V_1 = PA(s0,v0, edge_index,edge_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rotated and Translated inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 10 # Angle\n",
    "b = 0 # Translation factor\n",
    "F = 128\n",
    "num_nodes = 9\n",
    "\n",
    "v0 = torch.zeros(num_nodes,F,3, dtype=torch.float)\n",
    "# Translation\n",
    "translate = b*torch.ones(r_ij.shape[0], r_ij.shape[1])\n",
    "trans_r_ij = r_ij + translate\n",
    "# Rotation\n",
    "rot_mat = torch.tensor([[1,0,0],\n",
    "                       [0, np.cos(a), -np.sin(a)],\n",
    "                      [0, np.sin(a), np.cos(a)]], dtype = torch.float) \n",
    "rot_r_ij = (rot_mat@trans_r_ij.T).T\n",
    "\n",
    "# edge_attr: inter_atomic distances\n",
    "edge_index = radius_graph(rot_r_ij, r=1.70, batch=None, loop=False)\n",
    "row, col = edge_index\n",
    "edge_attr_st = (rot_r_ij[row] - rot_r_ij[col])\n",
    "#print(edge_index.dtype == torch.long)\n",
    "\n",
    "V_2 = PA(s0,v0, edge_index,edge_attr_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_out = (rot_mat@V_1[0].T).T # rotate output with unrotated inputs (taking only first node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_err = max((abs((V_2[0]-rot_out)/V_2[0])).flatten()) # max.error between rotated output of network with unrotated inputs, and output of network with rotated input.\n",
    "min_err = min((abs((V_2[0]-rot_out)/V_2[0])).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: tensor(7.4412e-05, grad_fn=<UnbindBackward>) min: tensor(0., grad_fn=<UnbindBackward>)\n"
     ]
    }
   ],
   "source": [
    "print('max:', max_err, 'min:', min_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formaldehyde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Paramerts\n",
    "# # F: Num. features, r_ij: cartesian positions\n",
    "# F = int(128/2)\n",
    "# num_nodes = 4\n",
    "# s0 = torch.rand(num_nodes,F, dtype=torch.float)\n",
    "# v0 = torch.zeros(num_nodes,F,3, dtype=torch.float)\n",
    "# s10 = torch.rand(num_nodes,F, dtype=torch.float)\n",
    "# v10 = torch.zeros(num_nodes,F,3, dtype=torch.float)\n",
    "# r_ij =  torch.tensor([[0.000000,  0.000000,  -0.537500],\n",
    "#   [0.000000,  0.000000,   0.662500],\n",
    "#   [0.000000,  0.866025,  -1.037500],\n",
    "#   [0.000000, -0.866025,  -1.037500]])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # edge_attr: inter_atomic distances\n",
    "# edge_index = radius_graph(r_ij, r=1.30, batch=None, loop=False)\n",
    "# row, col = edge_index\n",
    "# edge_attr = (r_ij[row] - r_ij[col])\n",
    "# #print(edge_index.dtype == torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PA = PaiNN(F, F, 4)\n",
    "# # S = PA(s0,v0, edge_index,edge_attr)\n",
    "# rev=RevPaiNN(F, F, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Paramerts\n",
    "# # F: Num. features, r_ij: cartesian positions\n",
    "# F = 128\n",
    "# num_nodes = 3\n",
    "# s0 = torch.rand(num_nodes,F, dtype=torch.float)\n",
    "# v0 = torch.zeros(num_nodes,F,3, dtype=torch.float)\n",
    "# r_ij =  torch.tensor([[0.000000,  0.000000,  0.000000],\n",
    "#    [0.758602,  0.000000,  0.504284],\n",
    "#   [0.758602,  0.000000,  -0.504284]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # edge_attr: inter_atomic distances\n",
    "# edge_index = radius_graph(r_ij, r=1.30, batch=None, loop=False)\n",
    "# row, col = edge_index\n",
    "# edge_attr = (r_ij[row] - r_ij[col])\n",
    "# #print(edge_index.dtype == torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PA = PaiNN(F, F, 3)\n",
    "# h20 = PA(s0,v0, edge_index,edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = UpdatePaiNN(F,F,4)\n",
    "# prep = Prepare_Message_Vector(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = Linear(128,128, bias = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vT = torch.transpose(v0, 1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.transpose(lin(vT),1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 128])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ijk,ijk->ij',c,c).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 128, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
